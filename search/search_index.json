{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ReconST: Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments","text":""},{"location":"#1-introduction","title":"1. Introduction","text":"<p>Existing single-cell resolution spatial transcriptomics platforms (such as MERFISH, seqFISH, and Xenium) do not generate transcriptome-wide gene expression profiles but rather target a limited subset of genes. Therefore, a crucial question is how to select a gene that can optimally recaptitulate the whole-transcriptome information structure.</p> <p>ReconST is a data-driven framework for designing optimal gene panels for targeted spatial transcriptomics experiments. The method uses a paired-scRNAseq dataset as input information, and outputs a gene set of any given size that best preserves the overall gene expression patterns. This achieved by training a gated autoencoder to identify the most informative genes for reconstructing the full transcriptome information. ReconST is implemented as a lightweight Python package with a simple, reproducible workflow for model training, gene-ranking, and exporting panels compatible with modern spatial transcriptomics platforms.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p>Automated end-to-end gene selection.</p> </li> <li> <p>Compact and interpretable gene panels</p> </li> <li> <p>Generally applicable to any biological system and technological platform.</p> </li> <li> <p>Scalable to large datasets (such as whole mouse brain atlas data).</p> </li> <li> <p>Easy-to-use Python API</p> </li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Lu, H., et al. \"Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments.\" bioRxiv (2025): 2025-10.</p>"},{"location":"#2-installation","title":"2. Installation","text":"<p>Install directly from GitHub:</p> <pre><code>pip install git+https://github.com/haoranlustat/ReconST.git\n</code></pre>"},{"location":"#3-quick-start","title":"3. Quick Start","text":"<pre><code>import reconst\nfrom reconst import (\n    FeatureScreeningAutoencoder,\n    prepare_common_genes,\n    create_data_loader,\n    train_model,\n    evaluate_model,\n    select_genes,\n)\n\n# 1) Prepare shared gene set\ncommon_genes = prepare_common_genes(sc_adata, merfish_adata)\n\n# 2) Build dataloader\nloader = create_data_loader(sc_adata[:, common_genes], batch_size=256)\n\n# 3) Train gated autoencoder\nmodel = FeatureScreeningAutoencoder(n_genes=len(common_genes))\ntrain_model(model, loader, n_epochs=1000)\n\n# 4) Select top genes\nselected_genes = select_genes(model, top_k=200)\n\n# 5) Optional: evaluate on spatial data\nmetrics = evaluate_model(model, merfish_adata[:, common_genes])\n</code></pre>"},{"location":"#4-tutorials","title":"4. Tutorials","text":"<p>A complete working example tutorial: Example.ipynb</p>"},{"location":"#5-method-overview","title":"5. Method Overview","text":"<p>ReconST uses a gated autoencoder architecture to identify genes that best reconstruct the full transcriptome when compressed to a small panel. A learnable gating layer assigns an importance weight to each gene, and an L1 sparsity penalty encourages most gates to approach zero so that the model focuses on a compact, informative subset of genes.</p> <p>During training, the gated expression matrix is passed through an encoder\u2013decoder network that learns a low-dimensional representation and reconstructs the original expression profile. Genes with consistently high gate values are considered informative, while those with near-zero weights are excluded. After convergence, the final gene panel is obtained from the non-zero gates or by selecting the top-ranked genes. This end-to-end formulation provides a simple and scalable way to learn biologically meaningful gene panels suitable for targeted spatial transcriptomics.</p>"},{"location":"#6-license","title":"6. License","text":"<p>ReconST is released under the MIT License.</p>"},{"location":"api/","title":"ReconST API Reference","text":"<p>ReconST provides a lightweight, autoencoder-based framework for gene panel selection in spatial transcriptomics. This page summarizes the key classes and functions, organized by workflow: data preparation, model definition, training, evaluation, and gene selection.</p>"},{"location":"api/#1-model","title":"1. Model","text":""},{"location":"api/#featurescreeningautoencoder","title":"FeatureScreeningAutoencoder","text":"<p>Autoencoder with a learnable feature-importance layer for gene selection.</p> <p>Architecture - Learnable gene-importance layer - Encoder: <code>input_size \u2192 512 \u2192 256 \u2192 embedding_size</code> - Decoder: <code>embedding_size \u2192 256 \u2192 512 \u2192 input_size</code></p> <p>Parameters - <code>input_size</code> (int): Number of genes - <code>embedding_size</code> (int): Latent dimension - <code>dp</code> (float): Dropout probability - <code>lk</code> (float): LeakyReLU negative slope  </p> <p>Attributes - <code>feature_importance</code>: Learnable gene weights - <code>encoder</code>, <code>decoder</code>: Sequential modules  </p> <p>Example</p> <pre><code>import torch\nfrom reconst import FeatureScreeningAutoencoder\n\nmodel = FeatureScreeningAutoencoder(input_size=2000, embedding_size=64)\nx = torch.randn(32, 2000)\nscreened, latent, recon = model(x)\n</code></pre>"},{"location":"api/#2-data-utilities","title":"2. Data Utilities","text":""},{"location":"api/#create_data_loaderadata-batch_size256-train_split08-shuffletrue","title":"create_data_loader(adata, batch_size=256, train_split=0.8, shuffle=True)","text":"<p>Create training and test DataLoaders from an AnnData object.</p> <p>Example</p> <pre><code>import scanpy as sc\nfrom reconst import create_data_loader\n\nadata = sc.read_h5ad(\"data.h5ad\")\ntrain_loader, test_loader = create_data_loader(adata, batch_size=128)\n</code></pre>"},{"location":"api/#prepare_common_genesadata1-adata2","title":"prepare_common_genes(adata1, adata2)","text":"<p>Find and align common genes between two datasets.</p>"},{"location":"api/#3-training","title":"3. Training","text":""},{"location":"api/#train_modelmodel-train_loader-test_loader-num_epochs20-lr1e-3-weight_decay1e-5-l_lambda1e-4-devicecpu","title":"train_model(model, train_loader, test_loader, num_epochs=20, lr=1e-3, weight_decay=1e-5, l_lambda=1e-4, device='cpu')","text":"<p>Train the autoencoder with MSE + L1 sparsity penalty.</p> <p>Example</p> <pre><code>from reconst import train_model, FeatureScreeningAutoencoder\n\nmodel = FeatureScreeningAutoencoder(2000, 64).to('cuda')\ntrain_losses, test_losses = train_model(\n    model, train_loader, test_loader,\n    num_epochs=50, lr=1e-3, l_lambda=1e-4, device='cuda'\n)\n</code></pre>"},{"location":"api/#4-evaluation","title":"4. Evaluation","text":""},{"location":"api/#evaluate_modelmodel-test_loader-gene_masknone-devicecpu","title":"evaluate_model(model, test_loader, gene_mask=None, device='cpu')","text":"<p>Compute reconstruction MSE with all genes or a selected subset.</p> <p>Example</p> <pre><code>loss = evaluate_model(model, test_loader)\n</code></pre>"},{"location":"api/#5-gene-selection","title":"5. Gene Selection","text":""},{"location":"api/#select_genesmodel-threshold0001","title":"select_genes(model, threshold=0.001)","text":"<p>Extract selected genes based on learned feature importance.</p> <p>Example</p> <pre><code>gene_mask, importances = select_genes(model, threshold=0.01)\nselected_names = adata.var_names[gene_mask]\n</code></pre>"},{"location":"api/#summary","title":"Summary","text":"<p>ReconST exposes a streamlined, end-to-end workflow:</p> <ol> <li>Load and align AnnData  </li> <li>Build DataLoaders  </li> <li>Initialize the autoencoder  </li> <li>Train with sparsity  </li> <li>Evaluate  </li> <li>Select informative genes  </li> </ol>"},{"location":"example/","title":"ReconST Example: Gene Panel Selection","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport copy\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\n\nimport reconst\nfrom reconst import FeatureScreeningAutoencoder, prepare_common_genes, create_data_loader\nfrom reconst import train_model, evaluate_model, select_genes\n</pre> import os import copy import scanpy as sc import pandas as pd import numpy as np import torch import matplotlib.pyplot as plt  import reconst from reconst import FeatureScreeningAutoencoder, prepare_common_genes, create_data_loader from reconst import train_model, evaluate_model, select_genes In\u00a0[\u00a0]: Copied! <pre># Load scRNA-seq data\nadata00 = sc.read_h5ad('../example_data/example_sc.h5ad')\nadata01 = copy.deepcopy(adata00)\n\n# Basic filtering\nsc.pp.filter_cells(adata01, min_genes=200)\nsc.pp.filter_genes(adata01, min_cells=100)\n\n# Normalization\nsc.pp.normalize_total(adata01, target_sum=1e4)\n\nprint(f'Number of cells after processing: {adata01.n_obs}')\nprint(f'Number of genes after processing: {adata01.n_vars}')\n\n# Get gene identifiers\ngene_identifier_1 = adata01.var_names.tolist()\n</pre> # Load scRNA-seq data adata00 = sc.read_h5ad('../example_data/example_sc.h5ad') adata01 = copy.deepcopy(adata00)  # Basic filtering sc.pp.filter_cells(adata01, min_genes=200) sc.pp.filter_genes(adata01, min_cells=100)  # Normalization sc.pp.normalize_total(adata01, target_sum=1e4)  print(f'Number of cells after processing: {adata01.n_obs}') print(f'Number of genes after processing: {adata01.n_vars}')  # Get gene identifiers gene_identifier_1 = adata01.var_names.tolist() In\u00a0[\u00a0]: Copied! <pre># Load MERFISH data\nMER_cell_metadata   = pd.read_csv(\"../example_data/example_merfish_cell_metadata.csv\")\nMER_ccf_coordinates = pd.read_csv(\"../example_data/example_merfish_ccf_coordinates.csv\")\nMER_gene            = pd.read_csv(\"../example_data/example_merfish_gene.csv\")\nMER_adata = sc.read_h5ad(\"../example_data/example_merfish.h5ad\")\n\ngene_identifier_2 = MER_gene['gene_identifier']\n\nprint(f'MERFISH - Cells: {MER_adata.n_obs}, Genes: {MER_adata.n_vars}')\n</pre> # Load MERFISH data MER_cell_metadata   = pd.read_csv(\"../example_data/example_merfish_cell_metadata.csv\") MER_ccf_coordinates = pd.read_csv(\"../example_data/example_merfish_ccf_coordinates.csv\") MER_gene            = pd.read_csv(\"../example_data/example_merfish_gene.csv\") MER_adata = sc.read_h5ad(\"../example_data/example_merfish.h5ad\")  gene_identifier_2 = MER_gene['gene_identifier']  print(f'MERFISH - Cells: {MER_adata.n_obs}, Genes: {MER_adata.n_vars}') <pre>MERFISH - Cells: 215278, Genes: 1122\n</pre> In\u00a0[4]: Copied! <pre># Find common genes between scRNA-seq and MERFISH data\nadata01_common, MER_adata_common, common_genes = prepare_common_genes(adata01, MER_adata)\n\nprint(f\"Number of genes in data 1: {len(gene_identifier_1)}\")\nprint(f\"Number of genes in data 2: {len(gene_identifier_2)}\")\nprint(f'Number of common genes: {len(common_genes)}')\nprint(f'scRNA-seq: {adata01_common.n_obs} cells, {adata01_common.n_vars} genes')\nprint(f'MERFISH: {MER_adata_common.n_obs} cells, {MER_adata_common.n_vars} genes')\n</pre> # Find common genes between scRNA-seq and MERFISH data adata01_common, MER_adata_common, common_genes = prepare_common_genes(adata01, MER_adata)  print(f\"Number of genes in data 1: {len(gene_identifier_1)}\") print(f\"Number of genes in data 2: {len(gene_identifier_2)}\") print(f'Number of common genes: {len(common_genes)}') print(f'scRNA-seq: {adata01_common.n_obs} cells, {adata01_common.n_vars} genes') print(f'MERFISH: {MER_adata_common.n_obs} cells, {MER_adata_common.n_vars} genes') <pre>Number of genes in data 1: 18873\nNumber of genes in data 2: 1122\nNumber of common genes: 1014\nscRNA-seq: 44310 cells, 1014 genes\nMERFISH: 215278 cells, 1014 genes\n</pre> In\u00a0[5]: Copied! <pre># Create data loaders for training (scRNA-seq)\ntrain_loader, test_loader_sc = create_data_loader(adata01_common, batch_size=256, train_split=0.8)\n\n# Create test loader for MERFISH\nfrom reconst.data import GeneExpressionDataset\nfrom torch.utils.data import DataLoader\n\nmatrix = MER_adata_common.X.toarray() if hasattr(MER_adata_common.X, \"toarray\") else MER_adata_common.X\nmerfish_dataset = GeneExpressionDataset(torch.tensor(matrix, dtype=torch.float32))\ntest_loader_merfish = DataLoader(merfish_dataset, batch_size=256, shuffle=False)\n</pre> # Create data loaders for training (scRNA-seq) train_loader, test_loader_sc = create_data_loader(adata01_common, batch_size=256, train_split=0.8)  # Create test loader for MERFISH from reconst.data import GeneExpressionDataset from torch.utils.data import DataLoader  matrix = MER_adata_common.X.toarray() if hasattr(MER_adata_common.X, \"toarray\") else MER_adata_common.X merfish_dataset = GeneExpressionDataset(torch.tensor(matrix, dtype=torch.float32)) test_loader_merfish = DataLoader(merfish_dataset, batch_size=256, shuffle=False) In\u00a0[8]: Copied! <pre># Initialize model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_size = adata01_common.n_vars\nembedding_size = 200\n\nmodel = FeatureScreeningAutoencoder(input_size, embedding_size, dp=0.05, lk=0.3).to(device)\n\n# Create results directory\nos.makedirs(\"./results\", exist_ok=True)\n\n# Train\ntrain_losses, test_losses = train_model(\n    model, train_loader, test_loader_sc, \n    num_epochs=20, lr=1e-3, weight_decay=1e-5, l_lambda=1e-4, device=device\n)\n\n# Save the trained model\ntorch.save(model.state_dict(), './results/autoencoder_common_genes.pth')\nprint(\"Model saved to './results/autoencoder_common_genes.pth'\")\n</pre> # Initialize model device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") input_size = adata01_common.n_vars embedding_size = 200  model = FeatureScreeningAutoencoder(input_size, embedding_size, dp=0.05, lk=0.3).to(device)  # Create results directory os.makedirs(\"./results\", exist_ok=True)  # Train train_losses, test_losses = train_model(     model, train_loader, test_loader_sc,      num_epochs=20, lr=1e-3, weight_decay=1e-5, l_lambda=1e-4, device=device )  # Save the trained model torch.save(model.state_dict(), './results/autoencoder_common_genes.pth') print(\"Model saved to './results/autoencoder_common_genes.pth'\") <pre>Epoch [1/20], Train: 0.4225, Test: 0.3557\nEpoch [2/20], Train: 0.3378, Test: 0.3255\nEpoch [3/20], Train: 0.3168, Test: 0.3094\nEpoch [4/20], Train: 0.3039, Test: 0.2988\nEpoch [5/20], Train: 0.2953, Test: 0.2921\nEpoch [6/20], Train: 0.2887, Test: 0.2854\nEpoch [7/20], Train: 0.2836, Test: 0.2817\nEpoch [8/20], Train: 0.2798, Test: 0.2782\nEpoch [9/20], Train: 0.2768, Test: 0.2757\nEpoch [10/20], Train: 0.2741, Test: 0.2730\nEpoch [11/20], Train: 0.2716, Test: 0.2714\nEpoch [12/20], Train: 0.2695, Test: 0.2692\nEpoch [13/20], Train: 0.2676, Test: 0.2679\nEpoch [14/20], Train: 0.2659, Test: 0.2667\nEpoch [15/20], Train: 0.2645, Test: 0.2654\nEpoch [16/20], Train: 0.2633, Test: 0.2643\nEpoch [17/20], Train: 0.2625, Test: 0.2638\nEpoch [18/20], Train: 0.2616, Test: 0.2632\nEpoch [19/20], Train: 0.2605, Test: 0.2629\nEpoch [20/20], Train: 0.2598, Test: 0.2622\nModel saved to './results/autoencoder_common_genes.pth'\n</pre> In\u00a0[9]: Copied! <pre># Plot training curves\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label='Training loss', color='black')\nplt.plot(test_losses, label='Testing loss', color='blue')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Testing Loss over Epochs')\nplt.legend()\nplt.savefig('./results/loss_curve_common_genes.png')\nplt.show()\n\nprint(\"Final training loss: \", train_losses[-1])\nprint(\"Final testing loss: \", test_losses[-1])\n</pre> # Plot training curves plt.figure(figsize=(10, 6)) plt.plot(train_losses, label='Training loss', color='black') plt.plot(test_losses, label='Testing loss', color='blue') plt.xlabel('Epochs') plt.ylabel('Loss') plt.title('Training and Testing Loss over Epochs') plt.legend() plt.savefig('./results/loss_curve_common_genes.png') plt.show()  print(\"Final training loss: \", train_losses[-1]) print(\"Final testing loss: \", test_losses[-1]) <pre>Final training loss:  0.25980988693705426\nFinal testing loss:  0.26220912837573246\n</pre> In\u00a0[10]: Copied! <pre># Select genes based on importance threshold\ngenes_mask, feature_importances = select_genes(model, threshold=0.001)\n\nprint(f'Selected genes: {np.sum(genes_mask)}/{len(genes_mask)}')\n</pre> # Select genes based on importance threshold genes_mask, feature_importances = select_genes(model, threshold=0.001)  print(f'Selected genes: {np.sum(genes_mask)}/{len(genes_mask)}') <pre>Selected genes: 395/1014\n</pre> In\u00a0[11]: Copied! <pre># Plot feature importance distribution\nplt.figure(figsize=(10, 6))\nplt.hist(feature_importances, bins=25)\nplt.title('Feature Importance Distribution')\nplt.xlabel('Weight')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n</pre> # Plot feature importance distribution plt.figure(figsize=(10, 6)) plt.hist(feature_importances, bins=25) plt.title('Feature Importance Distribution') plt.xlabel('Weight') plt.ylabel('Frequency') plt.grid(True) plt.show() In\u00a0[12]: Copied! <pre># Evaluate on MERFISH data\nloss_all = evaluate_model(model, test_loader_merfish, gene_mask=None, device=device)\nloss_selected = evaluate_model(model, test_loader_merfish, gene_mask=genes_mask, device=device)\n\nprint(f'Test Loss (all genes): {loss_all:.4f}')\nprint(f'Test Loss (selected genes): {loss_selected:.4f}')\n</pre> # Evaluate on MERFISH data loss_all = evaluate_model(model, test_loader_merfish, gene_mask=None, device=device) loss_selected = evaluate_model(model, test_loader_merfish, gene_mask=genes_mask, device=device)  print(f'Test Loss (all genes): {loss_all:.4f}') print(f'Test Loss (selected genes): {loss_selected:.4f}') <pre>Test Loss (all genes): 0.1660\nTest Loss (selected genes): 0.1660\n</pre> In\u00a0[13]: Copied! <pre># Get selected gene symbols\nselected_gene_symbols = adata01_common.var['gene_symbol'][genes_mask].tolist()\nall_gene_symbols = adata01_common.var['gene_symbol']\n\nprint(f'Number of selected genes: {len(selected_gene_symbols)}')\nprint('Sample genes:', selected_gene_symbols[:10] if len(selected_gene_symbols) &gt;= 10 else selected_gene_symbols)\n</pre> # Get selected gene symbols selected_gene_symbols = adata01_common.var['gene_symbol'][genes_mask].tolist() all_gene_symbols = adata01_common.var['gene_symbol']  print(f'Number of selected genes: {len(selected_gene_symbols)}') print('Sample genes:', selected_gene_symbols[:10] if len(selected_gene_symbols) &gt;= 10 else selected_gene_symbols) <pre>Number of selected genes: 395\nSample genes: ['Oprk1', 'St18', 'Eya1', 'Col19a1', 'Pou3f3', 'Satb2', 'Erbb4', 'Spag16', 'Vwc2l', 'Tns1']\n</pre> In\u00a0[14]: Copied! <pre># Save results\ndf_importances = pd.DataFrame({\n    'gene_symbol': all_gene_symbols.values,\n    'importance': feature_importances\n})\ndf_importances.to_csv('./results/feature_importances.csv', index=False)\nprint(\"Saved feature importances to './results/feature_importances.csv'\")\n\ndf_selected = pd.DataFrame({'filtered_gene_symbol': selected_gene_symbols})\ndf_selected.to_csv('./results/filtered_gene_symbols.csv', index=False)\nprint(\"Saved filtered gene symbols to './results/filtered_gene_symbols.csv'\")\n</pre> # Save results df_importances = pd.DataFrame({     'gene_symbol': all_gene_symbols.values,     'importance': feature_importances }) df_importances.to_csv('./results/feature_importances.csv', index=False) print(\"Saved feature importances to './results/feature_importances.csv'\")  df_selected = pd.DataFrame({'filtered_gene_symbol': selected_gene_symbols}) df_selected.to_csv('./results/filtered_gene_symbols.csv', index=False) print(\"Saved filtered gene symbols to './results/filtered_gene_symbols.csv'\") <pre>Saved feature importances to './results/feature_importances.csv'\nSaved filtered gene symbols to './results/filtered_gene_symbols.csv'\n</pre>"},{"location":"example/#reconst-example-gene-panel-selection","title":"ReconST Example: Gene Panel Selection\u00b6","text":"<p>This notebook demonstrates using the ReconST package for optimal gene selection.</p>"},{"location":"example/#1-load-data","title":"1. Load Data\u00b6","text":""},{"location":"example/#note-please-download-the-processed-example-dataset-from-the-following-link-and-put-it-under-software_reconst-as-the-file-size-is-too-large-as-supplementary-file-in-submission-system","title":"Note: Please download the processed example dataset from the following link, and put it under \"software_ReconST/\", as the file size is too large as supplementary file in submission system.\u00b6","text":""},{"location":"example/#link-httpsoutlookuga-mysharepointcomfgpersonalhl25823_uga_eduetiblzrtppdho2_vrc_pxosbg838nep5wiqtvu8kar_dpqeci9jf8","title":"Link: https://outlookuga-my.sharepoint.com/:f:/g/personal/hl25823_uga_edu/EtiBLZrtPPdHo2_vRc_pxOsBg838neP5wiQTvu8kar_DpQ?e=Ci9JF8\u00b6","text":""},{"location":"example/#2-preprocess-find-common-genes","title":"2. Preprocess: Find Common Genes\u00b6","text":""},{"location":"example/#3-prepare-data-loaders","title":"3. Prepare Data Loaders\u00b6","text":""},{"location":"example/#4-train-model","title":"4. Train Model\u00b6","text":""},{"location":"example/#5-gene-selection-and-evaluation","title":"5. Gene Selection and Evaluation\u00b6","text":""}]}