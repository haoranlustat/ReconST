{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ReconST: Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments","text":"<p>ReconST is a Python package for automated and data-driven gene panel design in targeted spatial transcriptomics experiments. It uses a gated autoencoder to identify the most informative subset of genes for reconstructing transcriptomic structure, enabling efficient and biologically meaningful panel selection.</p> <p>Preprint: https://www.biorxiv.org/content/10.1101/2025.10.08.681071v1.abstract</p> <p>Citation: Lu, Haoran, et al. \"Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments.\" bioRxiv (2025): 2025-10. https://www.biorxiv.org/content/10.1101/2025.10.08.681071v1.abstract</p> <p>Key Features</p> <ul> <li>End-to-end gene selection using a gated autoencoder  </li> <li>L1-based sparsity for compact and interpretable gene panels  </li> <li>Directly operates on scRNA-seq data  </li> <li>Produces gene lists compatible with MERFISH, seqFISH, Xenium, MERSCOPE, etc.  </li> <li>Lightweight, minimal-dependency Python API  </li> </ul> <p>Installation</p> <p>Install directly from GitHub:</p> <p>pip install git+https://github.com/haoranlustat/ReconST.git</p> <p>Data Structure</p> <p>Expected directory layout:</p> <p>./example_data/   \u251c\u2500\u2500 example_sc.h5ad   \u251c\u2500\u2500 example_merfish.h5ad   \u251c\u2500\u2500 example_merfish_cell_metadata.csv   \u251c\u2500\u2500 example_merfish_ccf_coordinates.csv   \u2514\u2500\u2500 example_merfish_gene.csv</p> <p>./gene_panels/   \u2514\u2500\u2500 all_gene_symbols.csv   # optional utility output</p> <p>./results/   \u2514\u2500\u2500 (model outputs and selected gene panels)</p> <p>Quick Start</p> <p>import reconst from reconst import (     FeatureScreeningAutoencoder,     prepare_common_genes,     create_data_loader,     train_model,     evaluate_model,     select_genes, )</p>"},{"location":"#1-prepare-shared-gene-set","title":"1. Prepare shared gene set","text":"<p>common_genes = prepare_common_genes(sc_adata, merfish_adata)</p>"},{"location":"#2-build-dataloader","title":"2. Build dataloader","text":"<p>loader = create_data_loader(sc_adata[:, common_genes], batch_size=256)</p>"},{"location":"#3-train-gated-autoencoder","title":"3. Train gated autoencoder","text":"<p>model = FeatureScreeningAutoencoder(n_genes=len(common_genes)) train_model(model, loader, n_epochs=1000)</p>"},{"location":"#4-select-top-genes","title":"4. Select top genes","text":"<p>selected_genes = select_genes(model, top_k=200)</p>"},{"location":"#5-optional-evaluate-on-spatial-data","title":"5. Optional: evaluate on spatial data","text":"<p>metrics = evaluate_model(model, merfish_adata[:, common_genes])</p> <p>Method Overview</p> <p>ReconST introduces a learnable gating layer that assigns an importance weight to each gene. L1 regularization produces sparse selections, and genes with non-zero gate values form the final panel. This approach integrates gene scoring and representation learning into a simple, unified training pipeline.</p> <p>Documentation</p> <p>Full documentation and tutorials: https://haoranlustat.github.io/ReconST/</p>"},{"location":"api/","title":"API Reference","text":"<p>ReconST: Gene panel selection for spatial transcriptomics</p>"},{"location":"api/#reconst.FeatureScreeningAutoencoder","title":"<code>FeatureScreeningAutoencoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Autoencoder with learnable feature importance weights</p> Source code in <code>reconst/model.py</code> <pre><code>class FeatureScreeningAutoencoder(nn.Module):\n    \"\"\"Autoencoder with learnable feature importance weights\"\"\"\n\n    def __init__(self, input_size, embedding_size, dp=0.2, lk=0.2):\n        super(FeatureScreeningAutoencoder, self).__init__()\n\n        self.feature_importance = nn.Parameter(torch.ones(input_size))\n\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, 512),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(256, embedding_size),\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(embedding_size, 256),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(256, 512),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Linear(512, input_size),\n        )\n\n    def forward(self, x):\n        screened_features = x * self.feature_importance\n        encoded = self.encoder(screened_features)\n        decoded = self.decoder(encoded)\n        return screened_features, encoded, decoded\n</code></pre>"},{"location":"api/#reconst.create_data_loader","title":"<code>create_data_loader(adata, batch_size=256, train_split=0.8, shuffle=True)</code>","text":"<p>Create train and test data loaders from AnnData object</p> Source code in <code>reconst/data.py</code> <pre><code>def create_data_loader(adata, batch_size=256, train_split=0.8, shuffle=True):\n    \"\"\"Create train and test data loaders from AnnData object\"\"\"\n    matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n    gene_matrix = torch.tensor(matrix, dtype=torch.float32)\n    dataset = GeneExpressionDataset(gene_matrix)\n\n    train_size = int(train_split * len(dataset))\n    test_size = len(dataset) - train_size\n    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/#reconst.evaluate_model","title":"<code>evaluate_model(model, test_loader, gene_mask=None, device='cpu')</code>","text":"<p>Evaluate model on test data, optionally with gene filtering</p> Source code in <code>reconst/trainer.py</code> <pre><code>def evaluate_model(model, test_loader, gene_mask=None, device='cpu'):\n    \"\"\"Evaluate model on test data, optionally with gene filtering\"\"\"\n    criterion = nn.MSELoss()\n    model.eval()\n    test_loss = 0\n\n    with torch.no_grad():\n        for data in test_loader:\n            genes = data.to(device)\n\n            if gene_mask is not None:\n                if not isinstance(gene_mask, torch.Tensor):\n                    gene_mask = torch.tensor(gene_mask)\n                gene_mask = gene_mask.to(device)\n                filtered_genes = genes * gene_mask\n            else:\n                filtered_genes = genes\n\n            _, _, outputs = model(filtered_genes)\n            loss = criterion(outputs, genes)\n            test_loss += loss.item() * genes.size(0)\n\n    test_loss /= len(test_loader.dataset)\n    return test_loss\n</code></pre>"},{"location":"api/#reconst.prepare_common_genes","title":"<code>prepare_common_genes(adata1, adata2)</code>","text":"<p>Find common genes between two datasets and filter both</p> Source code in <code>reconst/data.py</code> <pre><code>def prepare_common_genes(adata1, adata2):\n    \"\"\"Find common genes between two datasets and filter both\"\"\"\n    genes1 = set(adata1.var_names)\n    genes2 = set(adata2.var_names)\n    common_genes = list(genes1.intersection(genes2))\n\n    genes_to_keep1 = [gene in common_genes for gene in adata1.var_names]\n    genes_to_keep2 = [gene in common_genes for gene in adata2.var_names]\n\n    adata1_common = adata1[:, genes_to_keep1].copy()\n    adata2_common = adata2[:, genes_to_keep2].copy()\n\n    # Align gene order\n    adata2_common = adata2_common[:, adata1_common.var_names].copy()\n\n    return adata1_common, adata2_common, common_genes\n</code></pre>"},{"location":"api/#reconst.select_genes","title":"<code>select_genes(model, threshold=0.001)</code>","text":"<p>Select genes based on feature importance threshold</p> Source code in <code>reconst/trainer.py</code> <pre><code>def select_genes(model, threshold=0.001):\n    \"\"\"Select genes based on feature importance threshold\"\"\"\n    feature_importances = model.feature_importance.data.cpu().numpy()\n    genes_mask = feature_importances &gt;= threshold\n    return genes_mask, feature_importances\n</code></pre>"},{"location":"api/#reconst.train_model","title":"<code>train_model(model, train_loader, test_loader, num_epochs=20, lr=0.001, weight_decay=1e-05, l_lambda=0.0001, device='cpu')</code>","text":"<p>Train the autoencoder model</p> Source code in <code>reconst/trainer.py</code> <pre><code>def train_model(model, train_loader, test_loader, num_epochs=20, lr=1e-3,\n                weight_decay=1e-5, l_lambda=1e-4, device='cpu'):\n    \"\"\"Train the autoencoder model\"\"\"\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    train_losses = []\n    test_losses = []\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n\n        for data in train_loader:\n            genes = data.to(device)\n            screened_features, _, outputs = model(genes)\n\n            loss = criterion(outputs, genes)\n            l1_penalty = l_lambda * torch.norm(model.feature_importance, p=1)\n            total_loss = loss + l1_penalty\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * genes.size(0)\n\n        train_loss /= len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        # Evaluate on test data\n        model.eval()\n        test_loss = 0\n        with torch.no_grad():\n            for data in test_loader:\n                genes = data.to(device)\n                _, _, outputs = model(genes)\n                loss = criterion(outputs, genes)\n                test_loss += loss.item() * genes.size(0)\n\n        test_loss /= len(test_loader.dataset)\n        test_losses.append(test_loss)\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Train: {train_loss:.4f}, Test: {test_loss:.4f}')\n\n    return train_losses, test_losses\n</code></pre>"},{"location":"usage/","title":"Basic usage","text":"<pre><code>from reconst import prepare_common_genes, train_model, select_genes\n</code></pre> <p>(details later)</p>"}]}