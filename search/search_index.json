{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ReconST: Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments","text":""},{"location":"#1-introduction","title":"1. Introduction","text":"<p>ReconST is a data-driven framework for designing optimal gene panels for targeted spatial transcriptomics experiments. Modern spatial transcriptomics platforms such as MERFISH, seqFISH, Xenium, and MERSCOPE can only measure a limited number of genes, making the choice of panel crucial for capturing transcriptomic structure and spatial organization. ReconST addresses this challenge by learning which genes best preserve global expression patterns and biological variation when compressed to a small panel.</p> <p>The method uses a gated autoencoder trained on scRNA-seq data to identify the most informative genes for reconstructing the full transcriptome. The resulting gene panel preserves cell-type structure and spatial patterns when transferred to spatial datasets, as demonstrated using a high-resolution mouse brain MERFISH atlas. ReconST is implemented as a lightweight Python package with a simple, reproducible workflow for model training, gene-ranking, and exporting panels compatible with modern spatial transcriptomics platforms.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>End-to-end gene selection using a gated autoencoder  </li> <li>L1-based sparsity for compact and interpretable gene panels  </li> <li>Directly operates on scRNA-seq data  </li> <li>Lightweight and easy-to-use Python API  </li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Lu, H., et al. \"Optimal Gene Panel Selection for Targeted Spatial Transcriptomics Experiments.\" bioRxiv (2025): 2025-10.</p>"},{"location":"#2-installation","title":"2. Installation","text":"<p>Install directly from GitHub:</p> <pre><code>pip install git+https://github.com/haoranlustat/ReconST.git\n</code></pre>"},{"location":"#3-quick-start","title":"3. Quick Start","text":"<pre><code>import reconst\nfrom reconst import (\n    FeatureScreeningAutoencoder,\n    prepare_common_genes,\n    create_data_loader,\n    train_model,\n    evaluate_model,\n    select_genes,\n)\n\n# 1) Prepare shared gene set\ncommon_genes = prepare_common_genes(sc_adata, merfish_adata)\n\n# 2) Build dataloader\nloader = create_data_loader(sc_adata[:, common_genes], batch_size=256)\n\n# 3) Train gated autoencoder\nmodel = FeatureScreeningAutoencoder(n_genes=len(common_genes))\ntrain_model(model, loader, n_epochs=1000)\n\n# 4) Select top genes\nselected_genes = select_genes(model, top_k=200)\n\n# 5) Optional: evaluate on spatial data\nmetrics = evaluate_model(model, merfish_adata[:, common_genes])\n</code></pre>"},{"location":"#4-tutorials","title":"4. Tutorials","text":"<p>A complete working example tutorial:</p> <p>Example.ipynb</p>"},{"location":"#5-method-overview","title":"5. Method Overview","text":"<p>ReconST uses a gated autoencoder architecture to identify genes that best reconstruct the full transcriptome when compressed to a small panel. A learnable gating layer assigns an importance weight to each gene, and an L1 sparsity penalty encourages most gates to approach zero so that the model focuses on a compact, informative subset of genes.</p> <p>During training, the gated expression matrix is passed through an encoder\u2013decoder network that learns a low-dimensional representation and reconstructs the original expression profile. Genes with consistently high gate values are considered informative, while those with near-zero weights are excluded. After convergence, the final gene panel is obtained from the non-zero gates or by selecting the top-ranked genes. This end-to-end formulation provides a simple and scalable way to learn biologically meaningful gene panels suitable for targeted spatial transcriptomics.</p>"},{"location":"#6-documentation","title":"6. Documentation","text":"<p>Full documentation and tutorials:</p> <p>https://haoranlustat.github.io/ReconST/</p>"},{"location":"api/","title":"API Reference","text":"<p>ReconST: Gene panel selection for spatial transcriptomics</p>"},{"location":"api/#reconst.FeatureScreeningAutoencoder","title":"<code>FeatureScreeningAutoencoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Autoencoder with learnable feature importance weights</p> Source code in <code>reconst/model.py</code> <pre><code>class FeatureScreeningAutoencoder(nn.Module):\n    \"\"\"Autoencoder with learnable feature importance weights\"\"\"\n\n    def __init__(self, input_size, embedding_size, dp=0.2, lk=0.2):\n        super(FeatureScreeningAutoencoder, self).__init__()\n\n        self.feature_importance = nn.Parameter(torch.ones(input_size))\n\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, 512),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(256, embedding_size),\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(embedding_size, 256),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Dropout(dp),\n            nn.Linear(256, 512),\n            nn.LeakyReLU(lk, inplace=True),\n            nn.Linear(512, input_size),\n        )\n\n    def forward(self, x):\n        screened_features = x * self.feature_importance\n        encoded = self.encoder(screened_features)\n        decoded = self.decoder(encoded)\n        return screened_features, encoded, decoded\n</code></pre>"},{"location":"api/#reconst.create_data_loader","title":"<code>create_data_loader(adata, batch_size=256, train_split=0.8, shuffle=True)</code>","text":"<p>Create train and test data loaders from AnnData object</p> Source code in <code>reconst/data.py</code> <pre><code>def create_data_loader(adata, batch_size=256, train_split=0.8, shuffle=True):\n    \"\"\"Create train and test data loaders from AnnData object\"\"\"\n    matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n    gene_matrix = torch.tensor(matrix, dtype=torch.float32)\n    dataset = GeneExpressionDataset(gene_matrix)\n\n    train_size = int(train_split * len(dataset))\n    test_size = len(dataset) - train_size\n    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/#reconst.evaluate_model","title":"<code>evaluate_model(model, test_loader, gene_mask=None, device='cpu')</code>","text":"<p>Evaluate model on test data, optionally with gene filtering</p> Source code in <code>reconst/trainer.py</code> <pre><code>def evaluate_model(model, test_loader, gene_mask=None, device='cpu'):\n    \"\"\"Evaluate model on test data, optionally with gene filtering\"\"\"\n    criterion = nn.MSELoss()\n    model.eval()\n    test_loss = 0\n\n    with torch.no_grad():\n        for data in test_loader:\n            genes = data.to(device)\n\n            if gene_mask is not None:\n                if not isinstance(gene_mask, torch.Tensor):\n                    gene_mask = torch.tensor(gene_mask)\n                gene_mask = gene_mask.to(device)\n                filtered_genes = genes * gene_mask\n            else:\n                filtered_genes = genes\n\n            _, _, outputs = model(filtered_genes)\n            loss = criterion(outputs, genes)\n            test_loss += loss.item() * genes.size(0)\n\n    test_loss /= len(test_loader.dataset)\n    return test_loss\n</code></pre>"},{"location":"api/#reconst.prepare_common_genes","title":"<code>prepare_common_genes(adata1, adata2)</code>","text":"<p>Find common genes between two datasets and filter both</p> Source code in <code>reconst/data.py</code> <pre><code>def prepare_common_genes(adata1, adata2):\n    \"\"\"Find common genes between two datasets and filter both\"\"\"\n    genes1 = set(adata1.var_names)\n    genes2 = set(adata2.var_names)\n    common_genes = list(genes1.intersection(genes2))\n\n    genes_to_keep1 = [gene in common_genes for gene in adata1.var_names]\n    genes_to_keep2 = [gene in common_genes for gene in adata2.var_names]\n\n    adata1_common = adata1[:, genes_to_keep1].copy()\n    adata2_common = adata2[:, genes_to_keep2].copy()\n\n    # Align gene order\n    adata2_common = adata2_common[:, adata1_common.var_names].copy()\n\n    return adata1_common, adata2_common, common_genes\n</code></pre>"},{"location":"api/#reconst.select_genes","title":"<code>select_genes(model, threshold=0.001)</code>","text":"<p>Select genes based on feature importance threshold</p> Source code in <code>reconst/trainer.py</code> <pre><code>def select_genes(model, threshold=0.001):\n    \"\"\"Select genes based on feature importance threshold\"\"\"\n    feature_importances = model.feature_importance.data.cpu().numpy()\n    genes_mask = feature_importances &gt;= threshold\n    return genes_mask, feature_importances\n</code></pre>"},{"location":"api/#reconst.train_model","title":"<code>train_model(model, train_loader, test_loader, num_epochs=20, lr=0.001, weight_decay=1e-05, l_lambda=0.0001, device='cpu')</code>","text":"<p>Train the autoencoder model</p> Source code in <code>reconst/trainer.py</code> <pre><code>def train_model(model, train_loader, test_loader, num_epochs=20, lr=1e-3,\n                weight_decay=1e-5, l_lambda=1e-4, device='cpu'):\n    \"\"\"Train the autoencoder model\"\"\"\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    train_losses = []\n    test_losses = []\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n\n        for data in train_loader:\n            genes = data.to(device)\n            screened_features, _, outputs = model(genes)\n\n            loss = criterion(outputs, genes)\n            l1_penalty = l_lambda * torch.norm(model.feature_importance, p=1)\n            total_loss = loss + l1_penalty\n\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * genes.size(0)\n\n        train_loss /= len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        # Evaluate on test data\n        model.eval()\n        test_loss = 0\n        with torch.no_grad():\n            for data in test_loader:\n                genes = data.to(device)\n                _, _, outputs = model(genes)\n                loss = criterion(outputs, genes)\n                test_loss += loss.item() * genes.size(0)\n\n        test_loss /= len(test_loader.dataset)\n        test_losses.append(test_loss)\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Train: {train_loss:.4f}, Test: {test_loss:.4f}')\n\n    return train_losses, test_losses\n</code></pre>"},{"location":"example/","title":"ReconST Example: Gene Panel Selection","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport copy\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\n\nimport reconst\nfrom reconst import FeatureScreeningAutoencoder, prepare_common_genes, create_data_loader\nfrom reconst import train_model, evaluate_model, select_genes\n</pre> import os import copy import scanpy as sc import pandas as pd import numpy as np import torch import matplotlib.pyplot as plt  import reconst from reconst import FeatureScreeningAutoencoder, prepare_common_genes, create_data_loader from reconst import train_model, evaluate_model, select_genes In\u00a0[\u00a0]: Copied! <pre># Load scRNA-seq data\nadata00 = sc.read_h5ad('../example_data/example_sc.h5ad')\nadata01 = copy.deepcopy(adata00)\n\n# Basic filtering\nsc.pp.filter_cells(adata01, min_genes=200)\nsc.pp.filter_genes(adata01, min_cells=100)\n\n# Normalization\nsc.pp.normalize_total(adata01, target_sum=1e4)\n\nprint(f'Number of cells after processing: {adata01.n_obs}')\nprint(f'Number of genes after processing: {adata01.n_vars}')\n\n# Get gene identifiers\ngene_identifier_1 = adata01.var_names.tolist()\n</pre> # Load scRNA-seq data adata00 = sc.read_h5ad('../example_data/example_sc.h5ad') adata01 = copy.deepcopy(adata00)  # Basic filtering sc.pp.filter_cells(adata01, min_genes=200) sc.pp.filter_genes(adata01, min_cells=100)  # Normalization sc.pp.normalize_total(adata01, target_sum=1e4)  print(f'Number of cells after processing: {adata01.n_obs}') print(f'Number of genes after processing: {adata01.n_vars}')  # Get gene identifiers gene_identifier_1 = adata01.var_names.tolist() In\u00a0[\u00a0]: Copied! <pre># Load MERFISH data\nMER_cell_metadata   = pd.read_csv(\"../example_data/example_merfish_cell_metadata.csv\")\nMER_ccf_coordinates = pd.read_csv(\"../example_data/example_merfish_ccf_coordinates.csv\")\nMER_gene            = pd.read_csv(\"../example_data/example_merfish_gene.csv\")\nMER_adata = sc.read_h5ad(\"../example_data/example_merfish.h5ad\")\n\ngene_identifier_2 = MER_gene['gene_identifier']\n\nprint(f'MERFISH - Cells: {MER_adata.n_obs}, Genes: {MER_adata.n_vars}')\n</pre> # Load MERFISH data MER_cell_metadata   = pd.read_csv(\"../example_data/example_merfish_cell_metadata.csv\") MER_ccf_coordinates = pd.read_csv(\"../example_data/example_merfish_ccf_coordinates.csv\") MER_gene            = pd.read_csv(\"../example_data/example_merfish_gene.csv\") MER_adata = sc.read_h5ad(\"../example_data/example_merfish.h5ad\")  gene_identifier_2 = MER_gene['gene_identifier']  print(f'MERFISH - Cells: {MER_adata.n_obs}, Genes: {MER_adata.n_vars}') <pre>MERFISH - Cells: 215278, Genes: 1122\n</pre> In\u00a0[4]: Copied! <pre># Find common genes between scRNA-seq and MERFISH data\nadata01_common, MER_adata_common, common_genes = prepare_common_genes(adata01, MER_adata)\n\nprint(f\"Number of genes in data 1: {len(gene_identifier_1)}\")\nprint(f\"Number of genes in data 2: {len(gene_identifier_2)}\")\nprint(f'Number of common genes: {len(common_genes)}')\nprint(f'scRNA-seq: {adata01_common.n_obs} cells, {adata01_common.n_vars} genes')\nprint(f'MERFISH: {MER_adata_common.n_obs} cells, {MER_adata_common.n_vars} genes')\n</pre> # Find common genes between scRNA-seq and MERFISH data adata01_common, MER_adata_common, common_genes = prepare_common_genes(adata01, MER_adata)  print(f\"Number of genes in data 1: {len(gene_identifier_1)}\") print(f\"Number of genes in data 2: {len(gene_identifier_2)}\") print(f'Number of common genes: {len(common_genes)}') print(f'scRNA-seq: {adata01_common.n_obs} cells, {adata01_common.n_vars} genes') print(f'MERFISH: {MER_adata_common.n_obs} cells, {MER_adata_common.n_vars} genes') <pre>Number of genes in data 1: 18873\nNumber of genes in data 2: 1122\nNumber of common genes: 1014\nscRNA-seq: 44310 cells, 1014 genes\nMERFISH: 215278 cells, 1014 genes\n</pre> In\u00a0[5]: Copied! <pre># Create data loaders for training (scRNA-seq)\ntrain_loader, test_loader_sc = create_data_loader(adata01_common, batch_size=256, train_split=0.8)\n\n# Create test loader for MERFISH\nfrom reconst.data import GeneExpressionDataset\nfrom torch.utils.data import DataLoader\n\nmatrix = MER_adata_common.X.toarray() if hasattr(MER_adata_common.X, \"toarray\") else MER_adata_common.X\nmerfish_dataset = GeneExpressionDataset(torch.tensor(matrix, dtype=torch.float32))\ntest_loader_merfish = DataLoader(merfish_dataset, batch_size=256, shuffle=False)\n</pre> # Create data loaders for training (scRNA-seq) train_loader, test_loader_sc = create_data_loader(adata01_common, batch_size=256, train_split=0.8)  # Create test loader for MERFISH from reconst.data import GeneExpressionDataset from torch.utils.data import DataLoader  matrix = MER_adata_common.X.toarray() if hasattr(MER_adata_common.X, \"toarray\") else MER_adata_common.X merfish_dataset = GeneExpressionDataset(torch.tensor(matrix, dtype=torch.float32)) test_loader_merfish = DataLoader(merfish_dataset, batch_size=256, shuffle=False) In\u00a0[8]: Copied! <pre># Initialize model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_size = adata01_common.n_vars\nembedding_size = 200\n\nmodel = FeatureScreeningAutoencoder(input_size, embedding_size, dp=0.05, lk=0.3).to(device)\n\n# Create results directory\nos.makedirs(\"./results\", exist_ok=True)\n\n# Train\ntrain_losses, test_losses = train_model(\n    model, train_loader, test_loader_sc, \n    num_epochs=20, lr=1e-3, weight_decay=1e-5, l_lambda=1e-4, device=device\n)\n\n# Save the trained model\ntorch.save(model.state_dict(), './results/autoencoder_common_genes.pth')\nprint(\"Model saved to './results/autoencoder_common_genes.pth'\")\n</pre> # Initialize model device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") input_size = adata01_common.n_vars embedding_size = 200  model = FeatureScreeningAutoencoder(input_size, embedding_size, dp=0.05, lk=0.3).to(device)  # Create results directory os.makedirs(\"./results\", exist_ok=True)  # Train train_losses, test_losses = train_model(     model, train_loader, test_loader_sc,      num_epochs=20, lr=1e-3, weight_decay=1e-5, l_lambda=1e-4, device=device )  # Save the trained model torch.save(model.state_dict(), './results/autoencoder_common_genes.pth') print(\"Model saved to './results/autoencoder_common_genes.pth'\") <pre>Epoch [1/20], Train: 0.4225, Test: 0.3557\nEpoch [2/20], Train: 0.3378, Test: 0.3255\nEpoch [3/20], Train: 0.3168, Test: 0.3094\nEpoch [4/20], Train: 0.3039, Test: 0.2988\nEpoch [5/20], Train: 0.2953, Test: 0.2921\nEpoch [6/20], Train: 0.2887, Test: 0.2854\nEpoch [7/20], Train: 0.2836, Test: 0.2817\nEpoch [8/20], Train: 0.2798, Test: 0.2782\nEpoch [9/20], Train: 0.2768, Test: 0.2757\nEpoch [10/20], Train: 0.2741, Test: 0.2730\nEpoch [11/20], Train: 0.2716, Test: 0.2714\nEpoch [12/20], Train: 0.2695, Test: 0.2692\nEpoch [13/20], Train: 0.2676, Test: 0.2679\nEpoch [14/20], Train: 0.2659, Test: 0.2667\nEpoch [15/20], Train: 0.2645, Test: 0.2654\nEpoch [16/20], Train: 0.2633, Test: 0.2643\nEpoch [17/20], Train: 0.2625, Test: 0.2638\nEpoch [18/20], Train: 0.2616, Test: 0.2632\nEpoch [19/20], Train: 0.2605, Test: 0.2629\nEpoch [20/20], Train: 0.2598, Test: 0.2622\nModel saved to './results/autoencoder_common_genes.pth'\n</pre> In\u00a0[9]: Copied! <pre># Plot training curves\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label='Training loss', color='black')\nplt.plot(test_losses, label='Testing loss', color='blue')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Testing Loss over Epochs')\nplt.legend()\nplt.savefig('./results/loss_curve_common_genes.png')\nplt.show()\n\nprint(\"Final training loss: \", train_losses[-1])\nprint(\"Final testing loss: \", test_losses[-1])\n</pre> # Plot training curves plt.figure(figsize=(10, 6)) plt.plot(train_losses, label='Training loss', color='black') plt.plot(test_losses, label='Testing loss', color='blue') plt.xlabel('Epochs') plt.ylabel('Loss') plt.title('Training and Testing Loss over Epochs') plt.legend() plt.savefig('./results/loss_curve_common_genes.png') plt.show()  print(\"Final training loss: \", train_losses[-1]) print(\"Final testing loss: \", test_losses[-1]) <pre>Final training loss:  0.25980988693705426\nFinal testing loss:  0.26220912837573246\n</pre> In\u00a0[10]: Copied! <pre># Select genes based on importance threshold\ngenes_mask, feature_importances = select_genes(model, threshold=0.001)\n\nprint(f'Selected genes: {np.sum(genes_mask)}/{len(genes_mask)}')\n</pre> # Select genes based on importance threshold genes_mask, feature_importances = select_genes(model, threshold=0.001)  print(f'Selected genes: {np.sum(genes_mask)}/{len(genes_mask)}') <pre>Selected genes: 395/1014\n</pre> In\u00a0[11]: Copied! <pre># Plot feature importance distribution\nplt.figure(figsize=(10, 6))\nplt.hist(feature_importances, bins=25)\nplt.title('Feature Importance Distribution')\nplt.xlabel('Weight')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n</pre> # Plot feature importance distribution plt.figure(figsize=(10, 6)) plt.hist(feature_importances, bins=25) plt.title('Feature Importance Distribution') plt.xlabel('Weight') plt.ylabel('Frequency') plt.grid(True) plt.show() In\u00a0[12]: Copied! <pre># Evaluate on MERFISH data\nloss_all = evaluate_model(model, test_loader_merfish, gene_mask=None, device=device)\nloss_selected = evaluate_model(model, test_loader_merfish, gene_mask=genes_mask, device=device)\n\nprint(f'Test Loss (all genes): {loss_all:.4f}')\nprint(f'Test Loss (selected genes): {loss_selected:.4f}')\n</pre> # Evaluate on MERFISH data loss_all = evaluate_model(model, test_loader_merfish, gene_mask=None, device=device) loss_selected = evaluate_model(model, test_loader_merfish, gene_mask=genes_mask, device=device)  print(f'Test Loss (all genes): {loss_all:.4f}') print(f'Test Loss (selected genes): {loss_selected:.4f}') <pre>Test Loss (all genes): 0.1660\nTest Loss (selected genes): 0.1660\n</pre> In\u00a0[13]: Copied! <pre># Get selected gene symbols\nselected_gene_symbols = adata01_common.var['gene_symbol'][genes_mask].tolist()\nall_gene_symbols = adata01_common.var['gene_symbol']\n\nprint(f'Number of selected genes: {len(selected_gene_symbols)}')\nprint('Sample genes:', selected_gene_symbols[:10] if len(selected_gene_symbols) &gt;= 10 else selected_gene_symbols)\n</pre> # Get selected gene symbols selected_gene_symbols = adata01_common.var['gene_symbol'][genes_mask].tolist() all_gene_symbols = adata01_common.var['gene_symbol']  print(f'Number of selected genes: {len(selected_gene_symbols)}') print('Sample genes:', selected_gene_symbols[:10] if len(selected_gene_symbols) &gt;= 10 else selected_gene_symbols) <pre>Number of selected genes: 395\nSample genes: ['Oprk1', 'St18', 'Eya1', 'Col19a1', 'Pou3f3', 'Satb2', 'Erbb4', 'Spag16', 'Vwc2l', 'Tns1']\n</pre> In\u00a0[14]: Copied! <pre># Save results\ndf_importances = pd.DataFrame({\n    'gene_symbol': all_gene_symbols.values,\n    'importance': feature_importances\n})\ndf_importances.to_csv('./results/feature_importances.csv', index=False)\nprint(\"Saved feature importances to './results/feature_importances.csv'\")\n\ndf_selected = pd.DataFrame({'filtered_gene_symbol': selected_gene_symbols})\ndf_selected.to_csv('./results/filtered_gene_symbols.csv', index=False)\nprint(\"Saved filtered gene symbols to './results/filtered_gene_symbols.csv'\")\n</pre> # Save results df_importances = pd.DataFrame({     'gene_symbol': all_gene_symbols.values,     'importance': feature_importances }) df_importances.to_csv('./results/feature_importances.csv', index=False) print(\"Saved feature importances to './results/feature_importances.csv'\")  df_selected = pd.DataFrame({'filtered_gene_symbol': selected_gene_symbols}) df_selected.to_csv('./results/filtered_gene_symbols.csv', index=False) print(\"Saved filtered gene symbols to './results/filtered_gene_symbols.csv'\") <pre>Saved feature importances to './results/feature_importances.csv'\nSaved filtered gene symbols to './results/filtered_gene_symbols.csv'\n</pre>"},{"location":"example/#reconst-example-gene-panel-selection","title":"ReconST Example: Gene Panel Selection\u00b6","text":"<p>This notebook demonstrates using the ReconST package for optimal gene selection.</p>"},{"location":"example/#1-load-data","title":"1. Load Data\u00b6","text":""},{"location":"example/#note-please-download-the-processed-example-dataset-from-the-following-link-and-put-it-under-software_reconst-as-the-file-size-is-too-large-as-supplementary-file-in-submission-system","title":"Note: Please download the processed example dataset from the following link, and put it under \"software_ReconST/\", as the file size is too large as supplementary file in submission system.\u00b6","text":""},{"location":"example/#link-httpsoutlookuga-mysharepointcomfgpersonalhl25823_uga_eduetiblzrtppdho2_vrc_pxosbg838nep5wiqtvu8kar_dpqeci9jf8","title":"Link: https://outlookuga-my.sharepoint.com/:f:/g/personal/hl25823_uga_edu/EtiBLZrtPPdHo2_vRc_pxOsBg838neP5wiQTvu8kar_DpQ?e=Ci9JF8\u00b6","text":""},{"location":"example/#2-preprocess-find-common-genes","title":"2. Preprocess: Find Common Genes\u00b6","text":""},{"location":"example/#3-prepare-data-loaders","title":"3. Prepare Data Loaders\u00b6","text":""},{"location":"example/#4-train-model","title":"4. Train Model\u00b6","text":""},{"location":"example/#5-gene-selection-and-evaluation","title":"5. Gene Selection and Evaluation\u00b6","text":""},{"location":"usage/","title":"Basic usage","text":"<pre><code>from reconst import prepare_common_genes, train_model, select_genes\n</code></pre> <p>(details later)</p>"}]}